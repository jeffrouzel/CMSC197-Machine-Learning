{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeff Rouzel A. Bat-og\n",
    "\n",
    "2021-03145\n",
    "\n",
    "https://github.com/jeffrouzel/CMSC197-Machine-Learning.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical operations, data manipulation and analysis\n",
    "import numpy as np              \n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "import email\n",
    "import re\n",
    "\n",
    "# For plotting the data             \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>email_content</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000/000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000/001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000/002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000/003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000/004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>126/017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>126/018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>126/019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>126/020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>126/021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location email_content  classification\n",
       "0      000/000           NaN               0\n",
       "1      000/001           NaN               1\n",
       "2      000/002           NaN               1\n",
       "3      000/003           NaN               0\n",
       "4      000/004           NaN               1\n",
       "...        ...           ...             ...\n",
       "37817  126/017           NaN               1\n",
       "37818  126/018           NaN               1\n",
       "37819  126/019           NaN               1\n",
       "37820  126/020           NaN               1\n",
       "37821  126/021           NaN               1\n",
       "\n",
       "[37822 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for Emails\n",
    "emaildf = pd.DataFrame(columns = ['location', 'email_content', 'classification'])\n",
    "classification = []\n",
    "location = []\n",
    "\n",
    "# read labels file, split the label and file location, then append lists as part of the dataframe\n",
    "with open(r'labels') as f:\n",
    "    for line in f:\n",
    "        label, locate = line.split()\n",
    "        if label == 'ham':\n",
    "            label = 0\n",
    "        elif label == 'spam':\n",
    "            label = 1\n",
    "        classification.append(label)\n",
    "        location.append(locate.replace('../data/', ''))\n",
    "\n",
    "emaildf['classification'] = classification\n",
    "emaildf['location'] = location\n",
    "emaildf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and Cleaning the Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading stopwords.txt file\n",
    "with open('stop_words.txt', 'r') as f:\n",
    "    stopwords = f.readlines()\n",
    "\n",
    "stopwords = [word[:-1] for word in stopwords]\n",
    "\n",
    "#stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html> B The price of the Mark's item is $29.99, and you can find it at http://example.com or www.shop.com. Email support at contact@example.com!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'price marks item find httpexamplecom wwwshopcom email support contactexamplecom'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getEmail(content):\n",
    "    msg = email.message_from_file(content)\n",
    "    \n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                body = part.get_payload()\n",
    "                return body\n",
    "    else:\n",
    "        body = msg.get_payload()\n",
    "        return body\n",
    "\n",
    "def cleanEmail(message):\n",
    "    bag_of_words = message.lower()\n",
    "    # bag_of_words = re.sub(r'\\b\\w{1}\\b', '', bag_of_words)      # Single characters\n",
    "    bag_of_words = re.sub(r'<.*?>', '', bag_of_words)\n",
    "    bag_of_words = re.sub(r'[^a-zA-Z\\n ]', '', bag_of_words)   # Punctuations, Numbers\n",
    "    msg = bag_of_words.split()\n",
    "\n",
    "    # Remove all stop words\n",
    "    msg = [word for word in msg if word not in stopwords]\n",
    "    bag_of_words = \" \".join(msg)\n",
    "    return bag_of_words\n",
    "\n",
    "# Test cleanEmail function\n",
    "testclean = \"<html> B The price of the Mark's item is $29.99, and you can find it at http://example.com or www.shop.com. Email support at contact@example.com!\"\n",
    "print(testclean)\n",
    "cleanEmail(testclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>email_content</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000/000</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000/001</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000/002</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000/003</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000/004</td>\n",
       "      <td>chauncey conferred luscious continued tonsillitis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000/005</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000/006</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000/007</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000/008</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000/009</td>\n",
       "      <td>magic perfect weekends httpothxurzfzwiwwfoehrr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location                                      email_content  classification\n",
       "0  000/000  mailing list queried weeks ago running set arc...               0\n",
       "1  000/001  luxury watches buy rolex rolex cartier bvlgari...               1\n",
       "2  000/002  academic qualifications prestigious nonacc red...               1\n",
       "3  000/003  greetings verify subscription planfans list ch...               0\n",
       "4  000/004  chauncey conferred luscious continued tonsillitis               1\n",
       "5  000/005           quiet quiet well straw poll plan running               0\n",
       "6  000/006  working departed totally bell labs recommended...               0\n",
       "7  000/007  nbc today body diet beaches magazines hollywoo...               1\n",
       "8  000/008  oil sector going crazy weekly gift kkpt thing ...               1\n",
       "9  000/009  magic perfect weekends httpothxurzfzwiwwfoehrr...               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the email files and cleaning \n",
    "\n",
    "email_contents = []\n",
    "\n",
    "for locate in emaildf['location']:\n",
    "    with open(f'data/{locate}', 'r', encoding = 'latin-1') as f:\n",
    "        content = cleanEmail(str(getEmail(f)))\n",
    "        email_contents.append((content))\n",
    "\n",
    "emaildf['email_content'] = email_contents\n",
    "emaildf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating Train and Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 21300 emails\n",
      "Test set length: 16522 emails\n"
     ]
    }
   ],
   "source": [
    "# Seperate the data between train and test set\n",
    "# Folders 0-70: Train Set  &&  Folders 71-127: Test set\n",
    "train_set = emaildf[emaildf['location'] < '071']\n",
    "test_set = emaildf[emaildf['location'] >= '071']\n",
    "\n",
    "# Check length of each set\n",
    "print(f'Train set length: {len(train_set)} emails')\n",
    "print(f'Test set length: {len(test_set)} emails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ham = train_set[train_set['classification'] == 0].reset_index()\n",
    "train_spam = train_set[train_set['classification'] == 1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>email_content</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000/000</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>000/003</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>000/005</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>000/006</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>000/010</td>\n",
       "      <td>greetings mass acknowledgement signed planfans...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>21270</td>\n",
       "      <td>070/270</td>\n",
       "      <td>equation generate prime numbers equation theor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>21271</td>\n",
       "      <td>070/271</td>\n",
       "      <td>equation generate prime numbers equation theor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>21288</td>\n",
       "      <td>070/288</td>\n",
       "      <td>dear dmdx users guidance generating dmdx item ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>21293</td>\n",
       "      <td>070/293</td>\n",
       "      <td>built handyboard works great testmotor passes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>21298</td>\n",
       "      <td>070/298</td>\n",
       "      <td>mounted isu infrared demodulator hb realised r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index location                                      email_content  \\\n",
       "0         0  000/000  mailing list queried weeks ago running set arc...   \n",
       "1         3  000/003  greetings verify subscription planfans list ch...   \n",
       "2         5  000/005           quiet quiet well straw poll plan running   \n",
       "3         6  000/006  working departed totally bell labs recommended...   \n",
       "4        10  000/010  greetings mass acknowledgement signed planfans...   \n",
       "...     ...      ...                                                ...   \n",
       "7518  21270  070/270  equation generate prime numbers equation theor...   \n",
       "7519  21271  070/271  equation generate prime numbers equation theor...   \n",
       "7520  21288  070/288  dear dmdx users guidance generating dmdx item ...   \n",
       "7521  21293  070/293  built handyboard works great testmotor passes ...   \n",
       "7522  21298  070/298  mounted isu infrared demodulator hb realised r...   \n",
       "\n",
       "      classification  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "7518               0  \n",
       "7519               0  \n",
       "7520               0  \n",
       "7521               0  \n",
       "7522               0  \n",
       "\n",
       "[7523 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ham Training set\n",
    "train_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>email_content</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>000/001</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>000/002</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>000/004</td>\n",
       "      <td>chauncey conferred luscious continued tonsillitis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>000/007</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>000/008</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13772</th>\n",
       "      <td>21294</td>\n",
       "      <td>070/294</td>\n",
       "      <td>txtadd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>21295</td>\n",
       "      <td>070/295</td>\n",
       "      <td>btijclnab binpqnejgmb httpgethighbizez bldb xi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>21296</td>\n",
       "      <td>070/296</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>21297</td>\n",
       "      <td>070/297</td>\n",
       "      <td>doctype html public wcdtd html transitionalen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>21299</td>\n",
       "      <td>070/299</td>\n",
       "      <td>httptmqmctoverpacenet suffering pain depressio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13777 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index location                                      email_content  \\\n",
       "0          1  000/001  luxury watches buy rolex rolex cartier bvlgari...   \n",
       "1          2  000/002  academic qualifications prestigious nonacc red...   \n",
       "2          4  000/004  chauncey conferred luscious continued tonsillitis   \n",
       "3          7  000/007  nbc today body diet beaches magazines hollywoo...   \n",
       "4          8  000/008  oil sector going crazy weekly gift kkpt thing ...   \n",
       "...      ...      ...                                                ...   \n",
       "13772  21294  070/294                                             txtadd   \n",
       "13773  21295  070/295  btijclnab binpqnejgmb httpgethighbizez bldb xi...   \n",
       "13774  21296  070/296  special offer adobe video collection adobe pre...   \n",
       "13775  21297  070/297  doctype html public wcdtd html transitionalen ...   \n",
       "13776  21299  070/299  httptmqmctoverpacenet suffering pain depressio...   \n",
       "\n",
       "       classification  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "...               ...  \n",
       "13772               1  \n",
       "13773               1  \n",
       "13774               1  \n",
       "13775               1  \n",
       "13776               1  \n",
       "\n",
       "[13777 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spam Training Set\n",
    "train_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWordsDict = Counter(\" \".join(train_set['email_content']).split()).most_common(10000)\n",
    "\n",
    "#Extracted Most common words to dataframe\n",
    "cwdf = pd.DataFrame(commonWordsDict, columns = ['words','total_occurences'])\n",
    "\n",
    "# Experiment (1000, 100, 50)\n",
    "#k = 50\n",
    "#k = 100\n",
    "#k = 1000\n",
    "#filtered_cwdf = cwdf[cwdf['total_occurences'] > k]\n",
    "#commonWordsDict = dict(zip(filtered_cwdf['words'], filtered_cwdf['total_occurences']))\n",
    "#commonWordsTuples = list(commonWordsDict.items())\n",
    "#commonWordsDict = commonWordsTuples\n",
    "#commonWordsDict[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Feature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the words dictionary for ham and spam train sets\n",
    "\n",
    "ham_word = {unique_words: [0] * len(train_ham) for unique_words, _ in commonWordsDict}\n",
    "spam_word = {unique_words: [0] * len(train_spam) for unique_words, _ in commonWordsDict}\n",
    "\n",
    "top_list = [key for key, _ in commonWordsDict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix for Ham Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ham Feature Set\n",
    "ham_wordDF = pd.DataFrame(ham_word)\n",
    "\n",
    "for i in train_ham.index:\n",
    "    frequency = dict(Counter(train_ham['email_content'][i].split()))\n",
    "    # Word frequency per row in the train ham set\n",
    "    for key, val in frequency.items():\n",
    "        if key in top_list:  \n",
    "            ham_wordDF.loc[i, key] += val\n",
    "\n",
    "featurematrix_ham = ham_wordDF.to_numpy()\n",
    "featurematrix_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix for Spam Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spam Feature Set\n",
    "spam_wordDF = pd.DataFrame(spam_word)\n",
    "\n",
    "# loop through the train spam set index\n",
    "for i in train_spam.index:\n",
    "    # Word frequency per row in the train spam set\n",
    "    frequency = dict(Counter(train_spam['email_content'][i].split()))\n",
    "    for key, val in frequency.items():\n",
    "        if key in top_list:\n",
    "            spam_wordDF.loc[i, key] += val\n",
    "\n",
    "featurematrix_spam = spam_wordDF.to_numpy()\n",
    "featurematrix_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of Ham = $\\frac{N_{ham}}{N_{total}}$\n",
    "\n",
    "Probability of Spam = $\\frac{N_{spam}}{N_{total}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIOR PROBABILITIES\n",
      "Ham: 0.3531924882629108\n",
      "Spam: 0.6468075117370892\n"
     ]
    }
   ],
   "source": [
    "#email_hamcount = len(train_ham)\n",
    "#email_spamcount = len(train_spam)\n",
    "#email_totalcount = len(train_set)\n",
    "\n",
    "email_hamcount = train_ham.shape[0]\n",
    "email_spamcount = train_spam.shape[0]\n",
    "email_totalcount = train_set.shape[0]\n",
    "\n",
    "prior_ham = email_hamcount/email_totalcount\n",
    "prior_spam = email_spamcount/email_totalcount\n",
    "\n",
    "print(\"PRIOR PROBABILITIES\")\n",
    "print(f\"Ham: {prior_ham}\")\n",
    "print(f\"Spam: {prior_spam}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the likelihood of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH LAPLACE SMOOTHING\n",
      "Likelihood Ham: [2.5037545889420402e-05, 0.00906942513071532, 0.00646346228723996, 0.0003420917232172655, 0.00022806346645900546, 0.00014740933362999222, 0.004121711258204473, 0.005068702024696852, 2.5037545889420402e-05, 0.005325960896651463]\n",
      "\n",
      "Likelihood Spam: [0.027920743239746734, 0.008015993576528288, 0.0008680450644600728, 0.007139610351671722, 0.007233091228989756, 0.00692093187080275, 0.0018128696459244844, 0.0005074759662333717, 0.006501937224252278, 8.34650690339586e-09]\n"
     ]
    }
   ],
   "source": [
    "# Array for storing values of likelihood\n",
    "likelihood_ham = {}\n",
    "likelihood_spam = {}\n",
    "\n",
    "# Word sum of ham and spam\n",
    "Ham_wordsum = np.sum(featurematrix_ham, axis = 0)\n",
    "Spam_wordsum = np.sum(featurematrix_spam, axis = 0)\n",
    "\n",
    "#Total sum in ham and spam\n",
    "Ham_totalWords = np.sum(Ham_wordsum)\n",
    "Spam_totalWords = np.sum(Spam_wordsum)\n",
    "\n",
    "#Experiment (2.0 , 1.0 , 0.5 , 0.1 , 0.005)\n",
    "#lambda_value = 2\n",
    "#lambda_value = 1\n",
    "#lambda_value = 0.5\n",
    "#lambda_value = 0.1\n",
    "lambda_value = 0.005\n",
    "# Computing the likelihood of each word with laplace smoothing\n",
    "for i in range(len(top_list)):\n",
    "    likely_Ham = (Ham_wordsum[i] + lambda_value)/(Ham_totalWords + lambda_value*(len(top_list)))\n",
    "    likely_Spam = (Spam_wordsum[i] + lambda_value)/(Spam_totalWords + lambda_value*(len(top_list)))\n",
    "\n",
    "    likelihood_ham[top_list[i]] = likely_Ham\n",
    "    likelihood_spam[top_list[i]] = likely_Spam\n",
    "\n",
    "ham_values = list(likelihood_ham.values())[:10]\n",
    "spam_values = list(likelihood_spam.values())[:10]\n",
    "\n",
    "print(\"WITH LAPLACE SMOOTHING\")\n",
    "print(f\"Likelihood Ham: {ham_values}\\n\")\n",
    "print(f\"Likelihood Spam: {spam_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyEmail(email_content, prior_ham, prior_spam, likelihood_ham, likelihood_spam, top_list):\n",
    "    # Log values of ham and spam probabilities\n",
    "    ham_logprob = np.log(prior_ham)\n",
    "    spam_logprob = np.log(prior_spam)\n",
    "\n",
    "    #Split into words\n",
    "    email_words = str(email_content).split()\n",
    "    for word in email_words:\n",
    "        if word in top_list:\n",
    "            if word in likelihood_ham:\n",
    "                ham_logprob += np.log(likelihood_ham[word])\n",
    "            else:\n",
    "                ham_logprob += 0                      # To handle word not found\n",
    "            if word in likelihood_spam:\n",
    "                spam_logprob += np.log(likelihood_spam[word])\n",
    "            else: \n",
    "                spam_logprob += 0\n",
    "            \n",
    "    if ham_logprob > spam_logprob :\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>email_content</th>\n",
       "      <th>classification</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>071/000</td>\n",
       "      <td>hesitantly derive perverse satisfaction clodho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>071/001</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>071/002</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>071/003</td>\n",
       "      <td>de ar wne cr doesnt matter ow real st mmed ia ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>071/004</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16517</th>\n",
       "      <td>126/017</td>\n",
       "      <td>great news expec ted infinex ventures infx pri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16518</th>\n",
       "      <td>126/018</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16519</th>\n",
       "      <td>126/019</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering pain depressio...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16520</th>\n",
       "      <td>126/020</td>\n",
       "      <td>prosperous future increased money earning powe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16521</th>\n",
       "      <td>126/021</td>\n",
       "      <td>moat coverall cytochemistry planeload salk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location                                      email_content  \\\n",
       "0      071/000  hesitantly derive perverse satisfaction clodho...   \n",
       "1      071/001  things perform experiment display will remain ...   \n",
       "2      071/002  best offer month viggra ci ialis vaiium xa naa...   \n",
       "3      071/003  de ar wne cr doesnt matter ow real st mmed ia ...   \n",
       "4      071/004  special offer adobe video collection adobe pre...   \n",
       "...        ...                                                ...   \n",
       "16517  126/017  great news expec ted infinex ventures infx pri...   \n",
       "16518  126/018  oil sector going crazy weekly gift kkpt thing ...   \n",
       "16519  126/019  httpvdtobjdocscaninfo suffering pain depressio...   \n",
       "16520  126/020  prosperous future increased money earning powe...   \n",
       "16521  126/021         moat coverall cytochemistry planeload salk   \n",
       "\n",
       "       classification  prediction  \n",
       "0                   1           1  \n",
       "1                   0           0  \n",
       "2                   1           1  \n",
       "3                   1           1  \n",
       "4                   1           1  \n",
       "...               ...         ...  \n",
       "16517               1           1  \n",
       "16518               1           1  \n",
       "16519               1           1  \n",
       "16520               1           1  \n",
       "16521               1           1  \n",
       "\n",
       "[16522 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_dict = {'location':[], 'prediction': []}\n",
    "\n",
    "for path, content in zip(test_set['location'], test_set['email_content']):\n",
    "    predicted_dict['location'].append(path) \n",
    "    prediction = classifyEmail(content, prior_ham, prior_spam, likelihood_ham, likelihood_spam, top_list)\n",
    "    \n",
    "    # Prediction to be added to the data frame\n",
    "    predicted_dict['prediction'].append(prediction) \n",
    "\n",
    "predicted_testDF = pd.DataFrame.from_dict(predicted_dict)\n",
    "\n",
    "test_with_predict = pd.merge(test_set, predicted_testDF, on='location')\n",
    "test_with_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails: 16522\n",
      "\n",
      "Emails Classified Correctly: 15255\n",
      "\n",
      "Percentage of Emails Correctly Classified: 92.3314368720494%\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for index, row in test_with_predict.iterrows():\n",
    "    if float(row['classification']) == float(row['prediction']):\n",
    "        success_count += 1\n",
    "        \n",
    "print(f\"Emails: {(len(test_set))}\\n\")\n",
    "print(f\"Emails Classified Correctly: {success_count}\\n\")\n",
    "print(f\"Percentage of Emails Correctly Classified: {success_count/len(test_set)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy =** $\\frac{TN+TP}{TN+TP+FN+FP}$\n",
    "\n",
    "**Recall =** $\\frac{TP}{TP+FN}$\n",
    "\n",
    "**Precision =** $\\frac{TP}{TP+FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positive (FP) - **0 and 1**<br>False Negative (FN) - **1 and 0**<br>True Positive (TP) - **1 and 1**<br>True Negative (TN) - **0 and 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9233143687204939\n",
      "Precision: 0.977268330431418\n",
      "Recall: 0.907319263583296\n"
     ]
    }
   ],
   "source": [
    "FP = ((test_with_predict['classification'] == 0) & (test_with_predict['prediction'] == 1)).sum()\n",
    "FN = ((test_with_predict['classification'] == 1) & (test_with_predict['prediction'] == 0)).sum()\n",
    "TP = ((test_with_predict['classification'] == 1) & (test_with_predict['prediction'] == 1)).sum()\n",
    "TN = ((test_with_predict['classification'] == 0) & (test_with_predict['prediction'] == 0)).sum()\n",
    "\n",
    "accuracy = ((TN+TP)/(TN+TP+FN+FP))\n",
    "recall = (TP/(TP+FN)) if (TP+FN) > 0 else 0\n",
    "precision = (TP/(TP+FP)) if (TP+FP) > 0 else 0\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the effect of removing stop words in terms of precision, recall, and accuracy? Show a plot or a table of these results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Experiment on the number of words used for training. Filter the dictionary to include only words occurring more than k times (1000 words, then k > 100, and k = 50 times). For example, the word “offer” appears 150 times, that means that it will be included in the dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def lambdaSmoothing(featurematrix_ham, featurematrix_spam, top_list, lambda_value):\n",
    "#    # Array for storing values of likelihood\n",
    "#    likelihood_ham = {}\n",
    "#    likelihood_spam = {}\n",
    "\n",
    "    # Word sum of ham and spam\n",
    "#    Ham_wordsum = np.sum(featurematrix_ham, axis = 0)\n",
    "#    Spam_wordsum = np.sum(featurematrix_spam, axis = 0)\n",
    "\n",
    "    #Total sum in ham and spam\n",
    "#    Ham_totalWords = np.sum(Ham_wordsum)\n",
    "#    Spam_totalWords = np.sum(Spam_wordsum)\n",
    "\n",
    "    # Computing the likelihood of each word with laplace smoothing\n",
    "#    for i in range(len(top_list)):\n",
    "#        likely_Ham = (Ham_wordsum[i] + lambda_value)/(Ham_totalWords + lambda_value*(len(top_list)))\n",
    "#        likely_Spam = (Spam_wordsum[i] + lambda_value)/(Spam_totalWords + lambda_value*(len(top_list)))\n",
    "\n",
    "#        likelihood_ham[top_list[i]] = likely_Ham\n",
    "#        likelihood_spam[top_list[i]] = likely_Spam\n",
    "\n",
    "#    return likelihood_ham, likelihood_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Discuss the results of the different parameters used for Lambda smoothing. Test it on 5 varying values of the λ (e.g. λ = 2.0, 1.0, 0.5, 0.1, 0.005), Evaluate performance metrics for each.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What are your recommendations to further improve the model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
